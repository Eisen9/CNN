# -*- coding: utf-8 -*-
"""cw2_step_allv2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g5gQ2b061wsMcNvmNTWIVjL3IIwABnYe
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# Device configuration
# Choose GPU in Runtime > Change runtime type > Hardware Accelerator
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyper-parameters
num_epochs = 20
batch_size = 16
test_batch_size = 4
learning_rate = 0.00001

# Seed the random generator to have reproducible results
seed = 666
np.random.seed(seed)
torch.manual_seed(seed)
if torch.cuda.is_available():
  # Make CuDNN Determinist
  torch.backends.cudnn.deterministic = True
  torch.cuda.manual_seed(seed)

classes = ('airplanes', 'cars', 'dog', 'faces', 'keyboard')

"""# Step 1"""

class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()

        # input channel size of 3; our images have 3 colour channels
        # output channel size is 64

        # 1.2 first hidden layer
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)
        self.batchN = nn.BatchNorm2d(64)
        #------------------------------------------------------------------#
        # 1.3 second hidden layer -- max pooling
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)
        #------------------------------------------------------------------#
        # 1.4 third hidden layer
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.batchN2 = nn.BatchNorm2d(64)
        #------------------------------------------------------------------#
        # 1.5 fourth hidden layer -- max pooling
        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)
        #------------------------------------------------------------------#
        # 1.6
        # fc: fully connected (fifth layer)
        # output of last output layer must by 5 (num of classes)

        self.fc1 = nn.Linear(57600, 5)

    def forward(self, x):

        x = self.conv1(x)
        x = self.batchN(x)
        x = F.relu(x)
        x = self.pool(x)
        x = self.conv2(x)
        x = self.batchN2(x)
        x = F.relu(x)
        x = self.pool2(x)

        # flatten tensor
        x = x.view(x.size()[0], -1)

        x = self.fc1(x)

        return x

"""# Step 2"""

# step 2
'''
Step 2. Define a loss function and the optimizer
1.	Use a classification Cross-Entropy loss;
2.	Use the ADAM optimizer;
3.	Try a learning rate of 0.01, 0.001, 0.0001, 0.00001, and discuss the results of different learning rates.

'''
import torch.optim as optim

# Try a learning rate of 0.01, 0.001, 0.0001, 0.00001, and discuss the results of different learning rates
def createLossAndOptimizer(net, learning_rate=learning_rate): # <- Please change learning rate from hyper parameters above
    # it combines softmax with negative log likelihood loss
    criterion = nn.CrossEntropyLoss()

    optimizer = optim.Adam(net.parameters(), lr=learning_rate)
    return criterion, optimizer

"""# Step 3

### 3.1: Load & Normalise the Data
"""

import os
from torch.utils.data import Dataset
import numpy as np
from skimage import io


class ImageDataset(Dataset):

  def __init__(self, root_dir, train=True, transform=None):
    self.root_dir = root_dir
    self.transform = transform
    if train:
      self.img_path = np.load(root_dir + 'img_list_train.npy')
    else:
      self.img_path = np.load(root_dir + 'img_list_test.npy')

  def __len__(self):
    return len(self.img_path)

  def __getitem__(self, idx):
    # read the image
    path = os.path.join(self.root_dir, self.img_path[idx])
    img = io.imread(path)
    
    # if the image is grayscale then expand to 3 channels (RGB)
    if len(img.shape) < 3:
      img = np.expand_dims(img, axis=-1)
      img = np.repeat(img, 3, axis=2)

    # determine the label of the image
    img_folder = self.img_path[idx].split('/')[-2]
    if img_folder =='airplanes':
      label = np.array(0)
    elif img_folder == 'cars':
      label = np.array(1)
    elif img_folder == 'dog':
      label = np.array(2)
    elif img_folder == 'faces':
      label = np.array(3)
    elif img_folder == 'keyboard':
      label = np.array(4)

    # reshape the image from HxWx3 to 3xHxW
    img_reshaped = np.zeros([3, img.shape[0], img.shape[1]])
    img_reshaped[0,:,:] = img[:,:,0]
    img_reshaped[1,:,:] = img[:,:,1]
    img_reshaped[2,:,:] = img[:,:,2]

    # normalise the image
    img_norm = np.zeros([3, img.shape[0], img.shape[1]])

    # Convert from [0, 255] to [0, 1]
    img_norm[0, :, :] = img_reshaped[0,:,:] / 255
    img_norm[1, :, :] = img_reshaped[1,:,:] / 255
    img_norm[2, :, :] = img_reshaped[2,:,:] / 255

    sample = {'img': torch.from_numpy(img_norm.astype(np.float32)), 'label': torch.from_numpy(label.T.astype(np.long))}

    if self.transform:
      sample['img'] = self.transform(sample['img'])
    else:
      # Convert from [0, 1] to [-1, 1]
      sample['img'][0, :, :] = (sample['img'][0,:,:] - 0.5) / 0.5
      sample['img'][1, :, :] = (sample['img'][1,:,:] - 0.5) / 0.5
      sample['img'][2, :, :] = (sample['img'][2,:,:] - 0.5) / 0.5


    return sample

from google.colab import drive
drive.mount('/content/drive')

root_dir = "drive/MyDrive/Liverpool/Assignments/Year 3/COMP338/project 2/Assignment2_SupplementaryMaterials/data/" # Move npy files to data folder

train_dataset = ImageDataset(root_dir, train=True)

"""### 3.2 & 3.3: Train the Network & Save the Final Model"""

import time
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler


def train(net, batch_size, n_epochs, l_rate):
  """
  Train a neural network and print statistics of the training

  -- Parameters --
  net : (PyTorch Neural Network)
  batch_size : (int)
  n_epochs : (int) Number of iterations on the training set
  l_rate : (float) Learning rate used by the optimizer
  """
  print("====== HYPERPARAMETERS ======")
  print("batch_size=", batch_size)
  print("n_epochs=", n_epochs)
  print("learning_rate=", l_rate)
  print("=" * 30)

  # 350 images in training set
  # Use 1/5 for validation
  n_training_samples = 280
  n_val_samples = 70

  train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))
  val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))
  
  train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)
  val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, sampler=val_sampler, num_workers=2) # Use larger batch size for validation to speed up computation

  n_minibatches = len(train_loader)

  criterion, optimizer = createLossAndOptimizer(net, l_rate)
  # Init variables for plotting the loss
  train_history = []
  val_history = []

  training_start_time = time.time()
  best_error = np.inf
  best_model_path = "best_model.pth"

  # Move model to GPU if possible
  net = net.to(device)

  for epoch in range(n_epochs):
    running_loss = 0.0
    print_every = n_minibatches // 10
    start_time = time.time()
    total_train_loss = 0

    for i, batch in enumerate(train_loader):
      inputs = batch['img']
      labels = batch['label']
      
      # Move tensors to correct device
      inputs, labels = inputs.to(device), labels.to(device)

      # Zero param gradients
      optimizer.zero_grad()

      # Forward & backward & optimize
      outputs = net(inputs)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()

      # print stats
      running_loss += loss.item()
      total_train_loss += loss.item()

      # print every 10th epoch
      if (i + 1) % (print_every + 1) == 0:
        print("Epoch {}, {:d}% \t train_loss: {:.2f} took: {:.2f}s".format(
              epoch + 1, int(100 * (i + 1) / n_minibatches), running_loss / print_every,
              time.time() - start_time))
        running_loss = 0.0
        start_time = time.time()
      
    train_history.append(total_train_loss / len(train_loader))

    total_val_loss = 0
    # Do a pass on the validation set
    # We don't need to compute gradient,
    # we save memory and computation using th.no_grad()
    with torch.no_grad():
      for batch in val_loader:
          inputs = batch['img']
          labels = batch['label']
          # Move tensors to correct device
          inputs, labels = inputs.to(device), labels.to(device)
          # Forward pass
          predictions = net(inputs)
          val_loss = criterion(predictions, labels)
          total_val_loss += val_loss.item()
        
    val_history.append(total_val_loss / len(val_loader))
    # Save model that performs best on validation set
    if total_val_loss < best_error:
        best_error = total_val_loss
        torch.save(net.state_dict(), best_model_path)

    print("Validation loss = {:.2f}".format(total_val_loss / len(val_loader)))

  print("Training Finished, took {:.2f}s".format(time.time() - training_start_time))

  # Load best model
  net.load_state_dict(torch.load(best_model_path))

  return train_history, val_history

net = ConvNet()

train_history, val_history = train(net, batch_size=batch_size, n_epochs=num_epochs, l_rate=learning_rate)

"""### 3.4 Plot the Losses"""

def plot_losses(train_history, val_history):
    x = np.arange(1, len(train_history) + 1)

    plt.figure(figsize=(8, 6))
    plt.plot(x, train_history, color='red', label="Training loss", linewidth=2)
    plt.plot(x, val_history, color='blue', label="Validation loss", linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(loc='upper right')
    plt.title("Evolution of the training and validation loss")
    plt.show()

plot_losses(train_history, val_history)

"""# Step 4"""

# Load saved model
net = ConvNet()
net = net.to(device)
net.load_state_dict(torch.load("best_model (0.00001, 74).pth"))
net.eval()

# Load test images
test_sampler = SubsetRandomSampler(np.arange(50, dtype=np.int64)) # 50 test images
test_set = ImageDataset(root_dir, train=False)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, sampler=test_sampler, num_workers=2)

"""### 4.1 Overall Accuracy"""

def dataset_accuracy(net, data_loader, name=""):
    correct = 0
    total = 0
    correctly_classified = []
    incorrectly_classified = []
    for batch in data_loader:
        images = batch['img']
        labels = batch['label']
        images, labels = images.to(device), labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)

        for i, prediction in enumerate(predicted):
          if prediction == labels[i]:
            correct += 1
            correctly_classified.append((batch['img'][i], labels[i], prediction))
          else:
            incorrectly_classified.append((batch['img'][i], labels[i], prediction))
            
    accuracy = 100 * float(correct) / total
    print('Accuracy of the network on the {} {} images: {:.2f} % (error: {:.2f} %)'.format(total, name, accuracy, (100 - accuracy)))
    return correctly_classified, incorrectly_classified

correctly_classified, incorrectly_classified = dataset_accuracy(net, test_loader, name="test")

"""### 4.2 Accuracy Per Class"""

def accuracy_per_class(net, data_loader):
    n_classes = 5
    # (real, predicted)
    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)

    for batch in data_loader:
        images = batch['img']
        labels = batch['label']
        images, labels = images.to(device), labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        for i in range(labels.shape[0]):
            confusion_matrix[labels[i], predicted[i]] += 1
            label = labels[i]

    print("{:<10} {:^10} {:>10}".format("Class", "Accuracy (%)", "Error (%)"))
    for i in range(n_classes):
        class_total = confusion_matrix[i, :].sum()
        class_correct = confusion_matrix[i, i]
        percentage_correct = 100.0 * float(class_correct) / class_total
        
        print('{:<10} {:^10.2f} {:>10.2f}'.format(classes[i], percentage_correct, (100 - percentage_correct)))
    return confusion_matrix

confusion_matrix = accuracy_per_class(net, test_loader)

"""### 4.3 Confusion Matrix"""

import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html
    :param cm: (numpy matrix) confusion matrix
    :param classes: [str]
    :param normalize: (bool)
    :param title: (str)
    :param cmap: (matplotlib color map)
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
    plt.figure(figsize=(8, 8))   
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

plot_confusion_matrix(confusion_matrix, classes)

"""### 4.4 Correctly and Incorrectly Classified Images"""

# functions to show an image
def imshow(img):
    """
    :param img: (PyTorch Tensor)
    """
    # unnormalize
    img = img / 2 + 0.5     
    # Convert tensor to numpy array
    npimg = img.numpy()
    # Color channel first -> color channel last
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

"""Correctly Classified"""

img_index = 0                                      # image index <-- change this to see other images
imshow(correctly_classified[img_index][0])         # image
print(classes[correctly_classified[img_index][1]]) # true class
print(classes[correctly_classified[img_index][2]]) # predicted class

"""Incorrectly Classified"""

img_index = 0                                        # image index <-- change this to see other images
imshow(incorrectly_classified[img_index][0])         # image
print(classes[incorrectly_classified[img_index][1]]) # true class
print(classes[incorrectly_classified[img_index][2]]) # predicted class

"""### 4.7 Transfer Learning"""

# Download ImageNet labels
!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

import torchvision.models as models
from torch.utils.data.sampler import SequentialSampler

# Load pretrained models
trained_models = []
trained_models.append(models.resnet18(pretrained=True))
trained_models.append(models.alexnet(pretrained=True))
trained_models.append(models.vgg16(pretrained=True))

for model in trained_models:
  model = model.to(device)
  model.eval()

image_num = 10
sampler = SequentialSampler(np.arange(image_num, dtype=np.int64))

# Load images with correct normalization for classification
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
normalized_set = ImageDataset(root_dir, train=False, transform=normalize)
normalized_loader = torch.utils.data.DataLoader(normalized_set, batch_size=image_num, sampler=sampler, num_workers=2)

# Load non-normalized images for display
image_set = ImageDataset(root_dir, train=False)
image_loader = torch.utils.data.DataLoader(image_set, batch_size=image_num, sampler=sampler, num_workers=2)

normalized_dict = next(iter(normalized_loader))
image_dict = next(iter(image_loader))

normalized_dict['img'] = normalized_dict['img'].to(device)

img_index = 0

imshow(image_dict['img'][img_index])

# Read the categories
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]

prob_str = ""
for i in range(len(trained_models)):
  if i == 0: prob_str += "ResNet18: "
  if i == 1: prob_str += "AlexNet: "
  if i == 2: prob_str += "VGG16: "
  output = trained_models[i](normalized_dict['img'])
  probabilities = F.softmax(output[img_index], dim=0)

  # Show top categories per image
  top5_prob, top5_catid = torch.topk(probabilities, 5)
  for i in range(top5_prob.size(0)):
      prob_str += categories[top5_catid[i]] + ", " + "{:.2f}".format(top5_prob[i].item()) + " | "
  prob_str += "\n"

print(prob_str)